{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588d02ce-7d71-4afe-a0c8-59f6d20c3727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Volumes/workspace/test-schema/test-volume/Employee_Attrition.csv\", header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0769802d-c798-4d74-9b98-fe559b102bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dept_count_df = df.groupBy(\"Department\").count()\n",
    "display(dept_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f528d10-fa94-453e-bb55-28e61492b956",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763979494784}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "high_risk_df = df.filter((df.Attrition == \"No\") & (df.JobSatisfaction < 3)) \\\n",
    "    .select(\"EmployeeNumber\", \"Department\", \"JobRole\", \"Attrition\", \"JobSatisfaction\")\n",
    "\n",
    "display(high_risk_df)\n",
    "\n",
    "high_risk_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"high_risk_attrition_employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3af1bf84-1cd9-484b-b4f1-e0eb52703154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list down delta table versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684cc8f3-d787-4471-b52a-de1d488edd5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_version = spark.read.format(\"delta\").option(\"versionAsOf\", 0).table(\"high_risk_attrition_employees\")\n",
    "display(df_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55f99859-0c23-4c91-a3b7-cf470d67b5c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the schema of the target table\n",
    "target_df = spark.table(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Align columns and types\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dummy_df_aligned = dummy_df.select(\n",
    "    [col(c).cast(target_df.schema[c].dataType) for c in target_df.columns]\n",
    ")\n",
    "\n",
    "# Append to the Delta table\n",
    "dummy_df_aligned.write.format(\"delta\").mode(\"append\").saveAsTable(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Display all rows including the newly added dummy row\n",
    "all_rows_df = spark.table(\"high_risk_attrition_employees\")\n",
    "display(all_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b27b2a78-06b9-48d5-9016-0a2567dc77da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da8b719-a3c4-4969-b242-2ee0c4b5bf08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Volumes/workspace/test-schema/test-volume/Employee_Attrition.csv\", header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b98ef2b-b924-4866-8c27-3815deb3d24e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dept_count_df = df.groupBy(\"Department\").count()\n",
    "display(dept_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f65ac494-a22f-48c1-9c1c-0ee0dd73a188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "high_risk_df = df.filter((df.Attrition == \"No\") & (df.JobSatisfaction < 3)) \\\n",
    "    .select(\"EmployeeNumber\", \"Department\", \"JobRole\", \"Attrition\", \"JobSatisfaction\")\n",
    "\n",
    "display(high_risk_df)\n",
    "\n",
    "high_risk_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"high_risk_attrition_employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c15d2e18-8f6f-4e69-bd41-604df5404634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list down delta table versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbc5e0c1-4401-4fde-8670-bf9192ae3a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_version = spark.read.format(\"delta\").option(\"versionAsOf\", 0).table(\"high_risk_attrition_employees\")\n",
    "display(df_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f95e8f3-c71c-472e-9105-933fad81999f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the schema of the target table\n",
    "target_df = spark.table(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Align columns and types\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dummy_df_aligned = dummy_df.select(\n",
    "    [col(c).cast(target_df.schema[c].dataType) for c in target_df.columns]\n",
    ")\n",
    "\n",
    "# Append to the Delta table\n",
    "dummy_df_aligned.write.format(\"delta\").mode(\"append\").saveAsTable(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Display all rows including the newly added dummy row\n",
    "all_rows_df = spark.table(\"high_risk_attrition_employees\")\n",
    "display(all_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38a87dca-8600-4c80-a2af-45e63ea61d7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_version = spark.read.format(\"delta\").option(\"versionAsOf\", 0).table(\"high_risk_attrition_employees\")\n",
    "display(df_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "572fba37-31ba-4b8d-8619-bf942cc2054f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Volumes/workspace/test-schema/test-volume/Employee_Attrition.csv\", header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8b0f51f-ad35-4eb3-ba02-645228c47935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dept_count_df = df.groupBy(\"Department\").count()\n",
    "display(dept_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "696cc6cb-e594-41c2-abe2-aa4e2d164d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "high_risk_df = df.filter((df.Attrition == \"No\") & (df.JobSatisfaction < 3)) \\\n",
    "    .select(\"EmployeeNumber\", \"Department\", \"JobRole\", \"Attrition\", \"JobSatisfaction\")\n",
    "\n",
    "display(high_risk_df)\n",
    "\n",
    "high_risk_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"high_risk_attrition_employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4138c209-0b55-4a0b-b638-8b337b5c3036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list down delta table versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "006ac105-3258-4be3-b6fc-93ad6a23543b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the schema of the target table\n",
    "target_df = spark.table(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Align columns and types\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dummy_df_aligned = dummy_df.select(\n",
    "    [col(c).cast(target_df.schema[c].dataType) for c in target_df.columns]\n",
    ")\n",
    "\n",
    "# Append to the Delta table\n",
    "dummy_df_aligned.write.format(\"delta\").mode(\"append\").saveAsTable(\"high_risk_attrition_employees\")\n",
    "\n",
    "# Display all rows including the newly added dummy row\n",
    "all_rows_df = spark.table(\"high_risk_attrition_employees\")\n",
    "display(all_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0e601f-6491-40ec-abdb-ba25a3517ec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "dt = DeltaTable.forName(spark, \"high_risk_attrition_employees\")\n",
    "history_df = dt.history()\n",
    "display(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef5a3f7d-610f-4020-94a2-9be7e9167802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_specific_version = spark.read.format(\"delta\").option(\"versionAsOf\", 4).table(\"high_risk_attrition_employees\")\n",
    "display(df_specific_version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Employee_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
